{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5634f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import TypeVar, Any\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "\n",
    "import litellm\n",
    "from litellm import completion\n",
    "from instructor import from_litellm, Mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44267459",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.drop_params = True  # watsonx.ai doesn't support `json_mode`\n",
    "client = from_litellm(completion, mode=Mode.JSON)  # create an instructor client from litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a response model\n",
    "class Response(BaseModel): # <--- BaseModel is a Pydantic class\n",
    "    \"\"\"The predicted emotion from a customer review.\"\"\"\n",
    "    answer: str = Field(..., description=\"One of Ekman's 7 emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bbb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define a prompt\n",
    "prompt = \"\"\"You are an emotion detection expert. Identify the emotion in the text and return it as a string.\n",
    "\"\"\"\n",
    "\n",
    "# make a request to the LLM\n",
    "response = client.chat.completions.create( \n",
    "            model=\"watsonx/mistralai/mistral-large\", \n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt, \n",
    "                }\n",
    "            ],\n",
    "            project_id=os.getenv(\"WX_PROJECT_ID_RAG\"), \n",
    "            apikey=os.getenv(\"WX_API_KEY\"),\n",
    "            api_base=os.getenv(\"WX_API_URL\"),\n",
    "            response_model=Response, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e2f1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_model = create_model(\n",
    "    \"MyResponseModel\", \n",
    "    reasoning=(str, Field(description=\"The short reasoning behind the answer\")),\n",
    "    answer=(str, Field(description=\"Your answer to the question\")),\n",
    "    __base__=BaseModel\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7295720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseResponse(BaseModel):\n",
    "    \"\"\"A default response model that stores a list of predicted Ekman emotions. We will use this to predict the emotions of a review.\"\"\"\n",
    "    answer: str\n",
    "\n",
    "ResponseType = TypeVar(\"ResponseType\", bound=BaseModel)\n",
    "\n",
    "class LLMCaller:\n",
    "    \"\"\"\n",
    "    A class to interact with a Large Language Model (LLM)\n",
    "    using the LiteLLM and Instructor libraries.\n",
    "    \n",
    "    Designed to send prompts and receive structured responses\n",
    "    as Pydantic models (e.g., predicted emotions).\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key: str, project_id: str, api_url: str, model_id: str, params: dict[str, Any]):\n",
    "        \"\"\"Initializes the LLMCaller with Watsonx credentials and configuration.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.project_id = project_id\n",
    "        self.api_url = api_url\n",
    "        self.model_id = model_id\n",
    "        self.params = params\n",
    "\n",
    "        litellm.drop_params = True\n",
    "        self.client = from_litellm(completion, mode=Mode.JSON)\n",
    "\n",
    "    def create_response_model(self, title: str, fields: dict) -> ResponseType:\n",
    "        \"\"\" Dynamically creates a Pydantic response model for the LLM's output.\n",
    "        Args:\n",
    "            title (str): The name of the response model.\n",
    "            fields (dict): A dictionary defining the fields of the response model.\n",
    "                           Keys are field names, and values are tuples of (type, Field).\n",
    "\n",
    "        Returns:\n",
    "            ResponseType: A dynamically created Pydantic model class.\n",
    "        \"\"\"\n",
    "        return create_model(title, **fields, __base__=BaseResponse)\n",
    "\n",
    "    def invoke(self, prompt: str, response_model: ResponseType = BaseResponse, **kwargs) -> ResponseType:\n",
    "        \"\"\" Sends a prompt to the LLM and retrieves a structured response.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The input prompt to send to the LLM.\n",
    "            response_model (ResponseType): The Pydantic model to structure the LLM's response.\n",
    "                                           Defaults to BaseResponse.\n",
    "            **kwargs: Additional arguments to pass to the LLM client.\n",
    "\n",
    "        Returns:\n",
    "            ResponseType: The structured response from the LLM, parsed into the specified response model.\n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_id,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt + \"\\n\\nRespond using this structure: \" + str(response_model.__annotations__)\n",
    "            }],\n",
    "            project_id=self.project_id,\n",
    "            apikey=self.api_key,\n",
    "            api_base=self.api_url,\n",
    "            response_model=response_model,\n",
    "            **kwargs\n",
    "        )\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e740ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = LLMCaller(\n",
    "    api_key=os.getenv(\"WX_API_KEY\"),\n",
    "    project_id=os.getenv(\"WX_PROJECT_ID_RAG\"),\n",
    "    api_url=os.getenv(\"WX_URL\"),\n",
    "    model_id=\"watsonx/mistralai/mistral-large\",\n",
    "    params={\"max_tokens\": 100}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf1a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the emotion definitions\n",
    "df_defs = pd.read_csv(\"data/oxford_ekman_emotions.csv\")\n",
    "emotion_definitions = dict(zip(df_defs[\"emotion\"], df_defs[\"definition\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a9c3d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionResponse(BaseModel):\n",
    "    emotions: list[str] = Field(..., description=\"The list of Ekman emotions expressed in the review.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87680c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmotionResponse(emotions=['sad'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"im sad\", response_model=EmotionResponse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd47c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you're feeling sad. How can I help you?\n",
      "Sadness is a natural emotion, and it's important to acknowledge and address it. Offering support is a first step to helping you feel better or seek the help you need if necessary. Expressing empathy and providing an opening for further conversation can often be comforting and helpful in understanding the reasons behind the sadness and finding ways to address them effectively. By doing so, I'm supporting your emotional well-being and aiming to connect with you in a meaningful way that may lead to a positive resolution or, at the very least, a sense of being heard and understood. If the feeling persists or worsens, it's also important to consider reaching out to a mental health professional for further assistance and guidance. Mental health and emotional well-being are crucial aspects of overall well-being, and professional help can often provide valuable insights and strategies to cope with and manage feelings of sadness and other mental health concerns. In the context of your message, acknowledging your feelings and offering help can also encourage you to share more about what you're going through, allowing for a better understanding of the situation and the provision of more personalized support and guidance. Ultimately, the goal is to help you feel supported, understood, and empowered to address and overcome the feelings of sadness you're experiencing, and to remind you that you're not alone in this journey and that help is available if needed.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\n",
    "    prompt=\"im sad\", \n",
    "    response_model=llm.create_response_model(  # create a response model dynamically\n",
    "        \"EmotionResponse\", \n",
    "        {\n",
    "            \"reasoning\": (str, Field(...)),\n",
    "            \"Emotion\": (str, Field\n",
    "                (\n",
    "                    ...,\n",
    "                    description=\"The emotion of the review.\"\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.answer)\n",
    "print(response.reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78050ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a398b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt sent to LLM:\n",
      "You are a helpful assistant that classifies customer reviews using Ekman's 7 emotions.\n",
      "Use ONLY the following emotion definitions:\n",
      "\n",
      "ANGER: A strong feeling of annoyance, displeasure, or hostility.\n",
      "DISGUST: A strong feeling of dislike or disapproval for something unpleasant or offensive.\n",
      "FEAR: An unpleasant emotion caused by the threat of danger, pain, or harm.\n",
      "JOY: A feeling of great pleasure and happiness.\n",
      "SADNESS: The condition or quality of being sad; sorrow; a feeling of unhappiness or grief.\n",
      "SURPRISE: A feeling of mild astonishment or shock caused by something unexpected.\n",
      "NEUTRAL: Not displaying any strong emotion or feeling; a lack of emotional expression.\n",
      "\n",
      "\n",
      "Classify the following review into one or more Ekman emotions:\n",
      "\n",
      "Review: \"I was furious at the lack of help and felt completely disrespected.\"\n",
      "List all matching emotions. If none apply, return ['neutral'].\n",
      "Predicted emotions: ['ANGER', 'DISGUST']\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235d81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
